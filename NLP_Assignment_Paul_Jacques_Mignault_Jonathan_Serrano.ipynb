{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">News Classification - by Paul Jacques Mignault & Jonathan Serrano Barbosa</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook [Jonathan Serrano Barbosa](https://www.linkedin.com/in/jonathan-serrano-barbosa-0723b762/) and [Paul Jacques Mignault](https://www.linkedin.com/in/paul-jacques-mignault/) developed a binary text classifier able to dissociate between fake news and real news. The team tried different approaches in the data pre-processing, modeling and feature extraction.\n",
    "\n",
    "***\n",
    "#### Summary of the process:\n",
    "***\n",
    "\n",
    "1. Importing Libraries\n",
    "\n",
    "2. Reading CSV\n",
    "\n",
    "3. Creating a Baseline\n",
    "\n",
    "4. Data Pre-Processing and Models Testing\n",
    "\n",
    "5. Feature Extraction\n",
    "\n",
    "6. Predicting on holdout/test set\n",
    "    \n",
    "\n",
    "***    \n",
    "#### Main Findings include:\n",
    "***\n",
    "\n",
    "- **Data to be used**: The best models used both text and title.\n",
    "\n",
    "\n",
    "- **Pre-Processing**: Extensive pre-processing led to decreased accuracy. Hence, we did minimalistic cleaning to the text.\n",
    "\n",
    "\n",
    "- **Vectorizer**: TF-IDF vectorizer performed best.\n",
    "\n",
    "\n",
    "- **Models**: Passive Aggressive Classifier was the best performing algorithm.\n",
    "\n",
    "\n",
    "- **POS**: Isolating different POS led to decent accuracy but did not beat our best model using full-text.\n",
    "\n",
    "\n",
    "\n",
    "***\n",
    "#### Key Take Aways:\n",
    "***\n",
    "\n",
    "- **Baseline**. Starting with a baseline model helps in creating a benchmark to understand model performance without pre-processing nor complex modeling. This serves in evaluating the impact of feature engineering (in this case feature extraction) and performance of models later developed.\n",
    "\n",
    "\n",
    "- **Pre-Processing**. It is best to work on the pre-processing iteratively, that is studying the impact of each function on the model, rather than going for deep cleaning from the beginning. In fact, during the exercise, we made the mistake of starting with extensive cleaning early on and that led us to reach a point at which the model performance kept decreasing. Hence, it took us days before we understood that we had to work backwords and identify which were the steps that led to decreased model performance until finding the optimal pre-processing.\n",
    "\n",
    "\n",
    "- **Modeling**. Rather than going for complex model it is best to 1) try different models selected rationally, that is - in this case - models frequently used for text classification and 2) run smaller grid searches on the best performing models rather than using brute force. Simpler models might work best.\n",
    "\n",
    "\n",
    "- **Feature Extraction**. Using feature extraction is useful in identifying how the different POS might help in modelling. Looking back at the exercise, starting with EDA on the features rather than focusing on using feature extraction for modeling, would have helped us in understand the structure of fake news vs real news and thereby in informing our data pre-processing steps.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">I. Importing Libraries</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main libraries used for the exercice are [nltk](https://www.nltk.org/) for the text cleaning, and [sklearn](https://scikit-learn.org/stable/) for the machine learning aspects of the task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import xgboost\n",
    "import requests\n",
    "import io\n",
    "import itertools \n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "\n",
    "from string import punctuation\n",
    "\n",
    "from nltk import word_tokenize, pos_tag, pos_tag_sents, DefaultTagger, UnigramTagger\n",
    "from nltk.util import ngrams\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.classify import MaxentClassifier, maxent\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize.treebank import TreebankWordDetokenizer\n",
    "\n",
    "from sklearn import model_selection, preprocessing, linear_model, naive_bayes, metrics, svm\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, VotingClassifier, BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict, train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.linear_model import LogisticRegression, PassiveAggressiveClassifier, SGDClassifier, RidgeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">II. Reading the CSV</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the file from github"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order for anyone to be able to run this notebook smoothly without having to change any directory path, the csv file was directly uploaded on to github. Hence, the file is accessible through a URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text label   X1   X2  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...  FAKE  NaN  NaN  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...  FAKE  NaN  NaN  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...  REAL  NaN  NaN  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...  FAKE  NaN  NaN  \n",
       "4  It's primary day in New York and front-runners...  REAL  NaN  NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the Training dataset\n",
    "url = \"https://raw.githubusercontent.com/paul-jm/Fake_News_Detection_NLP/master/fake_or_real_news_training.csv\"\n",
    "s = requests.get(url).content\n",
    "raw_data = pd.read_csv(io.StringIO(s.decode('utf-8')), sep=',')\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fixing the dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When reading the CSV, the team noticed that text from certain rows is moved to the columns X1 and X2. Similarly, labels are, in some instances moved to other cells. Therefore, the team created a function to correct the imperfections when reading the file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These 3 functions allow to retrive labels and re-integrate text from columns X1 and X2\n",
    "def isNaN(num):\n",
    "    return num != num\n",
    "\n",
    "def retrieve_label(df):\n",
    "    'This function retrieves the label should it have been moved to another cell upon reading the CSV'\n",
    "    for row in range(df.shape[0]):\n",
    "        if df.loc[row, 'X2'] == 'REAL' or df.loc[row, 'X2'] == 'FAKE':\n",
    "            df.loc[row,'news_label'] = df.loc[row,'X2']\n",
    "        elif df.loc[row, 'X1'] == 'REAL' or df.loc[row, 'X1'] == 'FAKE':\n",
    "            df.loc[row,'news_label'] = df.loc[row,'X1']\n",
    "        else:\n",
    "            df.loc[row,'news_label'] = df.loc[row,'label']\n",
    "    return df\n",
    "\n",
    "def fix_df(df):\n",
    "    'This function retrieves the text that has been shifted to cells X1 and X2 upon reading the CSV'\n",
    "    for row in range(df.shape[0]):\n",
    "        if isNaN(df.loc[row, 'label']) == False and df.loc[row, 'label'] != 'REAL' and df.loc[row, 'label'] != 'FAKE':\n",
    "            df.loc[row, 'text'] = df.loc[row, 'text'] + df.loc[row, 'label']\n",
    "        elif isNaN(df.loc[row, 'X1']) == False and df.loc[row, 'X1'] != 'REAL' and df.loc[row, 'X1'] != 'FAKE':\n",
    "            df.loc[row, 'text'] = df.loc[row, 'text'] + df.loc[row, 'X1']\n",
    "        elif isNaN(df.loc[row, 'X2']) == False and df.loc[row, 'X2'] != 'REAL' and df.loc[row, 'X2'] != 'FAKE':\n",
    "            df.loc[row, 'text'] = df.loc[row, 'text'] + df.loc[row, 'X2']\n",
    "    df = df.drop(columns = ['label', 'X1', 'X2'])\n",
    "    return df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>news_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8476</td>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10294</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3608</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10142</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>875</td>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0   8476                       You Can Smell Hillary’s Fear   \n",
       "1  10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "2   3608        Kerry to go to Paris in gesture of sympathy   \n",
       "3  10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "4    875   The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                text news_label  \n",
       "0  Daniel Greenfield, a Shillman Journalism Fello...       FAKE  \n",
       "1  Google Pinterest Digg Linkedin Reddit Stumbleu...       FAKE  \n",
       "2  U.S. Secretary of State John F. Kerry said Mon...       REAL  \n",
       "3  — Kaydee King (@KaydeeKing) November 9, 2016 T...       FAKE  \n",
       "4  It's primary day in New York and front-runners...       REAL  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Applying the functions created above\n",
    "\n",
    "df = retrieve_label(raw_data) \n",
    "df = fix_df(df) \n",
    "df.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">III. Creating a Baseline</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team began the exercice by creating a baseline. The baseline consists of a basic model, without any pre-processing. Three simple models, logistic regression, Multinomial Naive-Bayes and Linear Support Vector Machine, were tested. The models were tried with both a count vectorizer and a TF-IDF Vectorizer. However, best results were obtained with the TF-IDF Vectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting the ID as the index\n",
    "df = df.set_index('ID')\n",
    "\n",
    "# Creating the target column\n",
    "y = df.news_label "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>news_label</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary’s Fear</td>\n",
       "      <td>Daniel Greenfield, a Shillman Journalism Fello...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>U.S. Secretary of State John F. Kerry said Mon...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>— Kaydee King (@KaydeeKing) November 9, 2016 T...</td>\n",
       "      <td>FAKE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York: Why This Primary Matters</td>\n",
       "      <td>It's primary day in New York and front-runners...</td>\n",
       "      <td>REAL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "ID                                                         \n",
       "8476                        You Can Smell Hillary’s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875     The Battle of New York: Why This Primary Matters   \n",
       "\n",
       "                                                    text news_label  \n",
       "ID                                                                   \n",
       "8476   Daniel Greenfield, a Shillman Journalism Fello...       FAKE  \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...       FAKE  \n",
       "3608   U.S. Secretary of State John F. Kerry said Mon...       REAL  \n",
       "10142  — Kaydee King (@KaydeeKing) November 9, 2016 T...       FAKE  \n",
       "875    It's primary day in New York and front-runners...       REAL  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We chose a split of 70/30 in order to leave the algorithm sufficient data for training. Furthermore, we added a seed to ensure similar split of data when re-running the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df['text'], y, test_size=0.3, random_state=666)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we simply create and train our Count Vectorizer and TF-IDF Vectorizer on the training data created above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simple count vectorizer\n",
    "count_vectorizer = CountVectorizer()\n",
    "# Fit and transform the training data \n",
    "count_train = count_vectorizer.fit_transform(X_train)\n",
    "# Transform the test set \n",
    "count_test = count_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "# Fit and transform the training data \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "# Transform the test set \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team created a function to compare different models and display the results in a table ranked by accuracy. Hence, making it easy to compare different models evaluated through cross-validation. We used cross-validation in order to ensure (or limit) overfitting of our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Accuracy\n",
      "0  Logistic Regression    0.902\n",
      "1       Multinomial NB    0.881\n",
      "2           Linear SVM    0.863\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Multinomial NB', MultinomialNB()))\n",
    "models.append(('Linear SVM', LinearSVC()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "#with joblib.parallel_backend('dask'):\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, count_train, y_train, cv=10, n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), \n",
    "                                       columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Accuracy\n",
      "2           Linear SVM    0.924\n",
      "0  Logistic Regression    0.897\n",
      "1       Multinomial NB     0.75\n"
     ]
    }
   ],
   "source": [
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Multinomial NB', MultinomialNB()))\n",
    "models.append(('Linear SVM', LinearSVC()))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), \n",
    "                               columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">IV. Building Model: Data Pre-Processing and Models Testing</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Creating Functions for Pre-Processing </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Different pre-processing steps were tried. Not all functions that were developed by the team were implemented. In fact, the team noticed that extensive pre-processing led to decreasing model performance. Hence, we had to work backwords and iteratively discard pre-processing functions that did not improve the model (see # functions or the functions discareded function). Also we created the normalization function with optional steps in order to easily try different combinations of cleaning later on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions Used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "\n",
    "def basic_clean(dataframe):\n",
    "    'Function that takes the dataframe as an input and cleans it by removing punction, digits and strips'\n",
    "    #Removing punctuation\n",
    "    dataframe.title = dataframe.title.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    dataframe.text = dataframe.text.apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
    "    #Removing regular expressions\n",
    "    dataframe['title'] = dataframe['title'].str.replace('[^\\w\\s]',' ')\n",
    "    dataframe['text'] = dataframe['text'].str.replace('[^\\w\\s]',' ')\n",
    "    #Removing digits\n",
    "    #dataframe.title = dataframe.title.apply(lambda x: x.translate(str.maketrans('', '', string.digits)))\n",
    "    #dataframe.text = dataframe.text.apply(lambda x: x.translate(str.maketrans('','', string.digits)))\n",
    "    #Removing double spaces\n",
    "    #dataframe['title'] = dataframe['title'].str.replace('  ',' ')\n",
    "    #dataframe['text'] = dataframe['text'].str.replace('  ',' ')\n",
    "    #Removing strips\n",
    "    #dataframe['title'] = dataframe['title'].replace(r'\\s+|\\\\n', ' ', regex = True, inplace = False)\n",
    "    #dataframe['text'] = dataframe['text'].replace(r'\\s+|\\\\n', ' ', regex = True, inplace = False)\n",
    "    return dataframe\n",
    "\n",
    "def normalization(text, lowercase = False, remove_stops = False, prt_stemming = False, snb_stemming = False, lemmatization = False):\n",
    "    'Flexible function to try effect of removing stopwords and the different stemming techniques'\n",
    "    txt = str(text)\n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    if prt_stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "    if snb_stemming:\n",
    "        snb = SnowballStemmer('english')\n",
    "        txt = \" \".join([snb.stem(w) for w in txt.split()])\n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w, pos = 's') for w in txt.split()])\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions discarded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def advanced_clean(dataframe, column):\n",
    "    'Function that takes the dataframe as input and fixes most common contractions and regular expressions'\n",
    "    dataframe[column] = dataframe[column].str.replace(\"isn't\", \"is not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"aren't\", \"are not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"ain't\", \"am not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"won't\", \"will not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"didn't\", \"did not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"shan't\", \"shall not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"haven't\", \"have not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"hadn't\", \"had not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"hasn't\", \"has not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"don't\", \"do not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"wasn't\", \"was not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"weren't\", \"were not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"doesn't\", \"does not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"'s\", \" is\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"'re\", \" are\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"'m\", \" am\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"'d\", \" would\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"'ll\", \" will\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"can't\",\"cannot\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"'cause'\",\"because\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"could've\",\"could have\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"couldn't\", \"could not\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"he's\", \"he is\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"how'd\", \"how did\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"I'd've\", \"I would have\")\n",
    "    dataframe[column] = dataframe[column].str.replace(\"I've\", \"I have\")\n",
    "    return dataframe\n",
    "\n",
    "def remove_url(text):\n",
    "    'Function that takes the dataframe as input and removes URLs from text'\n",
    "    txt = str(text)\n",
    "    txt = re.sub(r'^https?:\\/\\/.*[\\r\\n]*', ' ', text, flags=re.MULTILINE)\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Step 1: Selecting data to use, vectorizer and narrowing down potential models </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective of the first step was to select the data to be used moving forward (text, title or text and title), to decide on the best vectorizer to use and, lastly, to test models that are generally used for similar tasks, that is text classification. In general, we noticed that the text explained more variance than the title but less than text and title combined, which was a first interesting finding at this stage. Similarly, this step 1 proved superior performance of the TF-IDF vectorizer compared to the count vectorizer.\n",
    "\n",
    "Main Findings:\n",
    "\n",
    "\n",
    "- Using title and text is best\n",
    "- TF-IDF beats Count Vectorizer\n",
    "- Passive Aggressive Classifier*, Ridge Classifier, and Linear SVM are the top 3 performing algorithms\n",
    "\n",
    "\n",
    "*In a passive aggressive classifier, the model updates only when misclassifying an instance, i.e. Aggressive, if not it keeps the model, i.e. Passive. This flexible model therefore adjusts to its errors. It appears that our particular dataset provides the algorithm with enough information for updating the model*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df.copy()\n",
    "df0['text'] = df0['text'].map(lambda x: normalization(x, lowercase=True, remove_stops=False, prt_stemming=True, snb_stemming = False, lemmatization = False))\n",
    "df0['title'] = df0['title'].map(lambda x: normalization(x, lowercase=True, remove_stops=False, prt_stemming=True, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Text Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Accuracy\n",
      "0  Logistic Regression    0.895\n",
      "7     Ridge Classifier    0.894\n",
      "4              XGBoost    0.886\n",
      "1       Multinomial NB    0.877\n",
      "6      Tree Classifier    0.865\n",
      "5    Passive Agressive    0.856\n",
      "2           Linear SVM    0.853\n",
      "3        Random Forest    0.816\n"
     ]
    }
   ],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df0['text'], y, test_size=0.3, random_state=666)\n",
    "\n",
    "# Creating the count vectorizer\n",
    "vect = CountVectorizer()\n",
    "count_train = vect.fit_transform(X_train)\n",
    "count_test = vect.transform(X_test)\n",
    "\n",
    "# Trying the different models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Multinomial NB', MultinomialNB()))\n",
    "models.append(('Linear SVM', LinearSVC()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('XGBoost', XGBClassifier()))\n",
    "models.append(('Passive Agressive',PassiveAggressiveClassifier()))\n",
    "models.append(('Tree Classifier',AdaBoostClassifier()))\n",
    "models.append(('Ridge Classifier',RidgeClassifier(solver='lsqr')))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, count_train,y_train,cv=5,n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Accuracy\n",
      "5    Passive Agressive    0.922\n",
      "2           Linear SVM    0.919\n",
      "7     Ridge Classifier    0.916\n",
      "4              XGBoost    0.902\n",
      "0  Logistic Regression    0.896\n",
      "6      Tree Classifier    0.876\n",
      "3        Random Forest     0.81\n",
      "1       Multinomial NB    0.749\n"
     ]
    }
   ],
   "source": [
    "# Creating the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Trying the different models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Multinomial NB', MultinomialNB()))\n",
    "models.append(('Linear SVM', LinearSVC()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('XGBoost', XGBClassifier()))\n",
    "models.append(('Passive Agressive',PassiveAggressiveClassifier()))\n",
    "models.append(('Tree Classifier',AdaBoostClassifier()))\n",
    "models.append(('Ridge Classifier',RidgeClassifier(solver='lsqr')))\n",
    "              \n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Title Only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Accuracy\n",
      "1       Multinomial NB     0.79\n",
      "0  Logistic Regression    0.789\n",
      "5    Passive Agressive    0.764\n",
      "2           Linear SVM    0.763\n",
      "7     Ridge Classifier    0.761\n",
      "3        Random Forest    0.736\n",
      "4              XGBoost    0.734\n",
      "6      Tree Classifier    0.723\n"
     ]
    }
   ],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df0['title'], y, test_size=0.3, random_state=666)\n",
    "\n",
    "# Creating the count vectorizer\n",
    "vect = CountVectorizer()\n",
    "count_train = vect.fit_transform(X_train)\n",
    "count_test = vect.transform(X_test)\n",
    "\n",
    "# Trying the different models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Multinomial NB', MultinomialNB()))\n",
    "models.append(('Linear SVM', LinearSVC()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('XGBoost', XGBClassifier()))\n",
    "models.append(('Passive Agressive',PassiveAggressiveClassifier()))\n",
    "models.append(('Tree Classifier',AdaBoostClassifier()))\n",
    "models.append(('Ridge Classifier',RidgeClassifier(solver='lsqr')))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, count_train,y_train,cv=5,n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Accuracy\n",
      "7     Ridge Classifier    0.803\n",
      "0  Logistic Regression    0.801\n",
      "2           Linear SVM    0.798\n",
      "1       Multinomial NB    0.791\n",
      "5    Passive Agressive    0.779\n",
      "3        Random Forest    0.737\n",
      "4              XGBoost    0.731\n",
      "6      Tree Classifier     0.73\n"
     ]
    }
   ],
   "source": [
    "# Creating the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Trying the different models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Multinomial NB', MultinomialNB()))\n",
    "models.append(('Linear SVM', LinearSVC()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('XGBoost', XGBClassifier()))\n",
    "models.append(('Passive Agressive',PassiveAggressiveClassifier()))\n",
    "models.append(('Tree Classifier',AdaBoostClassifier()))\n",
    "models.append(('Ridge Classifier',RidgeClassifier(solver='lsqr')))\n",
    "              \n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Title and Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Accuracy\n",
      "0  Logistic Regression      0.9\n",
      "7     Ridge Classifier      0.9\n",
      "4              XGBoost     0.89\n",
      "1       Multinomial NB    0.884\n",
      "2           Linear SVM    0.874\n",
      "6      Tree Classifier    0.873\n",
      "5    Passive Agressive    0.872\n",
      "3        Random Forest    0.799\n"
     ]
    }
   ],
   "source": [
    "# Merging Title and Text\n",
    "df0['titles_text'] = df0[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)\n",
    "\n",
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df0['titles_text'], y, test_size=0.3, random_state=666)\n",
    "\n",
    "# Creating the count vectorizer\n",
    "vect = CountVectorizer()\n",
    "count_train = vect.fit_transform(X_train)\n",
    "count_test = vect.transform(X_test)\n",
    "\n",
    "# Trying the different models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Multinomial NB', MultinomialNB()))\n",
    "models.append(('Linear SVM', LinearSVC()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('XGBoost', XGBClassifier()))\n",
    "models.append(('Passive Agressive',PassiveAggressiveClassifier()))\n",
    "models.append(('Tree Classifier',AdaBoostClassifier()))\n",
    "models.append(('Ridge Classifier',RidgeClassifier(solver='lsqr')))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, count_train,y_train,cv=5,n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Model Accuracy\n",
      "2           Linear SVM    0.924\n",
      "5    Passive Agressive    0.922\n",
      "7     Ridge Classifier    0.919\n",
      "4              XGBoost    0.903\n",
      "0  Logistic Regression    0.897\n",
      "6      Tree Classifier    0.885\n",
      "3        Random Forest    0.808\n",
      "1       Multinomial NB    0.755\n"
     ]
    }
   ],
   "source": [
    "# Creating the TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Trying the different models\n",
    "models = []\n",
    "models.append(('Logistic Regression', LogisticRegression()))\n",
    "models.append(('Multinomial NB', MultinomialNB()))\n",
    "models.append(('Linear SVM', LinearSVC()))\n",
    "models.append(('Random Forest', RandomForestClassifier()))\n",
    "models.append(('XGBoost', XGBClassifier()))\n",
    "models.append(('Passive Agressive',PassiveAggressiveClassifier()))\n",
    "models.append(('Tree Classifier',AdaBoostClassifier()))\n",
    "models.append(('Ridge Classifier',RidgeClassifier(solver='lsqr')))\n",
    "              \n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Step 2: Selecting Best Normalization Method with Top Performing Algorithms</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the findings in step 1, the team decided to move forward testing the three top performing models on text and title combined with the TF-IDF Vectorizer. Here the objective was to analyze the impact of the different pre-processing steps on the model performance. For this purpose, the team used a seed and tried all the different combinations of pre-processing using the *normalization* function and by using the # to block certain parts of the basic_clean function. Furthermore, when using lemmatizing the team studied the impact of using different pos argument and found that pos = 's', which stands for satellite adjectives (depedent adjective, i.e. adjective in a given context or epithet).\n",
    "\n",
    "Main Findings:\n",
    "\n",
    "- Model performs best when not removing stop words\n",
    "- Model performs best with lemmatizing on satellite adjectives (vs stemming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()\n",
    "basic_clean(df1)\n",
    "\n",
    "# Further cleaning\n",
    "df1['text'] = df1['text'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "df1['title'] = df1['title'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "\n",
    "# Lowercase and lemmatizing on satellite adjectives\n",
    "df1['text'] = df1['text'].map(lambda x: normalization(x, lowercase=False, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = True))\n",
    "df1['title'] = df1['title'].map(lambda x: normalization(x, lowercase=False, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['titles_text'] = df1[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>news_label</th>\n",
       "      <th>titles_text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8476</th>\n",
       "      <td>You Can Smell Hillary s Fear</td>\n",
       "      <td>Daniel Greenfield a Shillman Journalism Fellow...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>You Can Smell Hillary s Fear Daniel Greenfield...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10294</th>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "      <td>Google Pinterest Digg Linkedin Reddit Stumbleu...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Watch The Exact Moment Paul Ryan Committed Pol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3608</th>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy</td>\n",
       "      <td>US Secretary of State John F Kerry said Monday...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>Kerry to go to Paris in gesture of sympathy US...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10142</th>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "      <td>Kaydee King KaydeeKing November 9 2016 The les...</td>\n",
       "      <td>FAKE</td>\n",
       "      <td>Bernie supporters on Twitter erupt in anger ag...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>The Battle of New York Why This Primary Matters</td>\n",
       "      <td>Its primary day in New York and frontrunners H...</td>\n",
       "      <td>REAL</td>\n",
       "      <td>The Battle of New York Why This Primary Matter...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   title  \\\n",
       "ID                                                         \n",
       "8476                        You Can Smell Hillary s Fear   \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...   \n",
       "3608         Kerry to go to Paris in gesture of sympathy   \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...   \n",
       "875      The Battle of New York Why This Primary Matters   \n",
       "\n",
       "                                                    text news_label  \\\n",
       "ID                                                                    \n",
       "8476   Daniel Greenfield a Shillman Journalism Fellow...       FAKE   \n",
       "10294  Google Pinterest Digg Linkedin Reddit Stumbleu...       FAKE   \n",
       "3608   US Secretary of State John F Kerry said Monday...       REAL   \n",
       "10142  Kaydee King KaydeeKing November 9 2016 The les...       FAKE   \n",
       "875    Its primary day in New York and frontrunners H...       REAL   \n",
       "\n",
       "                                             titles_text  \n",
       "ID                                                        \n",
       "8476   You Can Smell Hillary s Fear Daniel Greenfield...  \n",
       "10294  Watch The Exact Moment Paul Ryan Committed Pol...  \n",
       "3608   Kerry to go to Paris in gesture of sympathy US...  \n",
       "10142  Bernie supporters on Twitter erupt in anger ag...  \n",
       "875    The Battle of New York Why This Primary Matter...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df1['titles_text'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               Model Accuracy\n",
      "1  Passive Agressive    0.938\n",
      "0         Linear SVM    0.934\n",
      "2   Ridge Classifier    0.931\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "models = []\n",
    "models.append(('Linear SVM', LinearSVC(random_state=69)))\n",
    "models.append(('Passive Agressive',PassiveAggressiveClassifier(random_state=69)))\n",
    "models.append(('Ridge Classifier',RidgeClassifier(solver='lsqr',random_state=69)))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "scoring = 'accuracy'\n",
    "\n",
    "for name, model in models:\n",
    "    cv_scores = cross_val_score(model, tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "    mean_score = round(np.mean(cv_scores), 3)\n",
    "    results.append(mean_score)\n",
    "    names.append(name)\n",
    "\n",
    "Models_comparison = pd.DataFrame(np.column_stack([names,results]), columns=['Model','Accuracy'])\n",
    "\n",
    "Models_comparison = Models_comparison.sort_values('Accuracy', ascending = False)\n",
    "\n",
    "print(Models_comparison)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Step 3: Tuning Hyperparameters from Best Performing Model</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, the team ran a Grid Search to identify the best set of hyperparameters both for the TF-IDF Vectorizer and for the Passive Aggressive Classifier. The challenge in this step was to select the right parameters to train our grid search on as well as the right ranges.\n",
    "\n",
    "Main Findings:\n",
    "\n",
    "- Best Parameters for Passive Aggressive Classifier: loss = 'hinge'\n",
    "- Best Parameters for the TF-IDF Vectorizer: max_df = 1.0, ngram_range = (1,2), norm = 'l2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9265395436073773\n",
      "Train score 1.0\n",
      "Test score 0.924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'PAC__loss': 'squared_hinge',\n",
       " 'tfidf__max_df': 0.75,\n",
       " 'tfidf__ngram_range': (1, 2),\n",
       " 'tfidf__norm': 'l2'}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer()),('PAC', PassiveAggressiveClassifier(random_state=69))])\n",
    "\n",
    "pipe_params = {'tfidf__ngram_range': [(1,2), (2,2), (1,3)],'tfidf__max_df':[0.5, 0.75, 1.0],'tfidf__norm':['l1','l2'],'PAC__loss':['hinge', 'squared_hinge']}\n",
    "\n",
    "gs_pac = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs_pac.fit(X_train, y_train);\n",
    "print(\"Best score:\", gs_pac.best_score_)\n",
    "print(\"Train score\", gs_pac.score(X_train, y_train))\n",
    "print(\"Test score\", round(gs_pac.score(X_test, y_test),3))\n",
    "pac_best = gs_pac.best_estimator_\n",
    "gs_pac.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.936\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df = 1.0, ngram_range = (1,2), norm = 'l2') \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(random_state=69, loss = 'hinge'), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Step 4: Comparing Individual Performance vs Stacked Model </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this stem, the team stacked the top 3 performing models, i.e. Linear SVC, Ridge Regression and Passive Aggressive Classifier, and compared the performance of the ensemble with the performance of the Passive Aggressive Classifier.\n",
    "\n",
    "Main Findings:\n",
    "\n",
    "- Passive Aggressive Classifier beats Ensemble (even with hyperparameters tunning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "SVM = LinearSVC(random_state = 69)\n",
    "Ridge = RidgeClassifier(solver='lsqr', random_state = 69)\n",
    "PAC = PassiveAggressiveClassifier(random_state = 69)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(estimators=[('Linear SVC', SVM), ('Ridge Regression', Ridge), ('Passive Aggressive Classifier', PAC)], voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.934\n"
     ]
    }
   ],
   "source": [
    "cv_scores = cross_val_score(ensemble, tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.9306033135354799\n",
      "Train score 0.9996874023132228\n",
      "Test score 0.924\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'tfidf__max_df': 0.75, 'tfidf__ngram_range': (1, 1), 'tfidf__norm': 'l2'}"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([('tfidf', TfidfVectorizer()),('PAC', VotingClassifier(estimators=[('Linear SVC', SVM), ('Ridge Regression', Ridge), ('Passive Aggressive Classifier', PAC)], voting='hard'))])\n",
    "pipe_params = {'tfidf__ngram_range': [(1,1), (1,2), (2,2), (1,3)],'tfidf__max_df':[0.5, 0.75, 1.0],'tfidf__norm':['l1','l2']}\n",
    "\n",
    "gs_pac = GridSearchCV(pipe, param_grid=pipe_params, cv=5)\n",
    "gs_pac.fit(X_train, y_train);\n",
    "print(\"Best score:\", gs_pac.best_score_)\n",
    "print(\"Train score\", gs_pac.score(X_train, y_train))\n",
    "print(\"Test score\", round(gs_pac.score(X_test, y_test),3))\n",
    "pac_best = gs_pac.best_estimator_\n",
    "gs_pac.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Discarded Option: Spelling Correction</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The team noticed that the text sometimes contained spelling mistakes. Hence, we took on the challenging task of  creating a function that uses the texblob library to correct eventual spelling mistakes in the text. However, because the function is computationally expensive (>7h00 running in a 32GB laptop), we ran it once and exported the results into a csv file that we have re-uploaded into github. Hence, there is no need to run the function when reading this notebook. If you would still like to do so remove the # from the cell below. \n",
    "\n",
    "The main reason the function was discarded is because of its sometimes inaccurate spelling corrections leading to little change to the model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install -U textblob\n",
    "#from textblob import TextBlob\n",
    "\n",
    "#def correct_spelling(dataframe):\n",
    "    #'Function that takes the dataframe as input and corrects spelling mistakes in text and title'\n",
    "    #dataframe['title'] = dataframe['title'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "    #dataframe['text'] = dataframe['text'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "    #return dataframe\n",
    "\n",
    "#correct_spelling(df)\n",
    "\n",
    "#df5 = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the new Training dataset\n",
    "#url = \"https://raw.githubusercontent.com/jonathanserrano1993/Fake_news_detection_NLP/master/new_training.csv\"\n",
    "#s = requests.get(url).content\n",
    "#df5 = pd.read_csv(io.StringIO(s.decode('utf-8')), sep=',')\n",
    "#df5.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5['text'] = df5['text'].map(lambda x: cleanData(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = True))\n",
    "#df5['title'] = df5['title'].map(lambda x: cleanData(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df5['titles_text'] = df5[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further tuning our best models\n",
    "\n",
    "#pipe = Pipeline([('tfidf', TfidfVectorizer()),('PAC', PassiveAggressiveClassifier(random_state = 11))])\n",
    "\n",
    "#pipe_params = {'tfidf__ngram_range': [(1,1), (2,2), (1,3)],'tfidf__max_df':[0.1, 0.5, 1.0],'tfidf__norm':['l1','l2']}\n",
    "\n",
    "#gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "#gs.fit(X_train, y_train);\n",
    "#print(\"Best score:\", gs.best_score_)\n",
    "#print(\"Train score\", gs.score(X_train, y_train))\n",
    "#print(\"Test score\", gs.score(X_test, y_test))\n",
    "#gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">V. Text Feature Extraction</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The section below extracts features from the articles in the train set, in order to quantify some of their attributes. For each article, the following elements were extracted:\n",
    "\n",
    "1/ The number of dates in each article. Fake news tend to appeal to emotions rather than state facts; the number of dates was extracted for every article through a regular expression. No text normalization function was applied. \n",
    "\n",
    "Following the removal of stopwords, the following features were extracted. The objective is to uncover whether fake news typically have more or fewer words, nouns, etc. Such a pattern would ideally ease their identification. All cases were left as they were when reading the .csv file, in order to best identify the proper nouns. \n",
    "\n",
    "2/ The proportion of tokens that had the POS tag starting with 'VB', i.e.  the number of verbs out of all the tokens in the text. \n",
    "\n",
    "3/ The proportion of tokens that had the POS tag starting with 'NN', i.e.  the number of nouns out of all the tokens in the text. \n",
    "\n",
    "4/ The proportion of tokens that had the POS tag starting with 'JJ', i.e.  the number of adjectives out of all the tokens in the text. \n",
    "\n",
    "5/ The proportion of tokens that had the POS tag starting with 'RB', i.e.  the number of adverbs out of all the tokens in the text. \n",
    "\n",
    "6/ The proportion of tokens that had the POS tag starting with 'JJS', i.e.  the number of superlative adjectives out of all the tokens in the text. \n",
    "\n",
    "7/ The proportion of tokens that had the POS tag starting with 'JJR', i.e.  the number of comparative adjectives out of all the tokens in the text. \n",
    "\n",
    "8/ The proportion of tokens that had the POS tag starting with 'NNP', i.e.  the number of proper nouns out of all the tokens in the text. \n",
    "\n",
    "After removing all capital letters and lemmatizing tokens, the following features were extracted from the combined title and text columns:\n",
    "\n",
    "9/ The number of tokens in the text, to determine if fake news tend to be shorter or longer than real news stories.  \n",
    "\n",
    "10/ The number of types out of the total number of tokens; this feature keeps track of the lexical diversity the journalist used to write the article. Real news story typically have richer vocabulary than fake stories, though this particular feature is biased towards longer articles, which do employ more types than shorter ones. \n",
    "\n",
    "As all 10 new features were numerical, they were scaled and their skewness was fixed where needed. Little correlation was observed between the numerical features and the target variable; the number of dates presented the highest correlation coefficient in absolute value of 0.39. \n",
    "\n",
    "The vectorized 'titles_text' column containing tokens from both titles and text colums was converted to a dataframe and concatenated  with the numerical features. In order to contain memory usage, the option 'shuffle' was set to false on the 'train_test_split' function, implying the model is highly biased towards initial order of the tuples. Comparing it directly with the other models in the present notebook would not be fair. However, the model performance while including any set of the 10 numerical features decreased accuracy by 0.5 to 1 percentage points. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Text Feature Extraction on Raw Data</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_raw = df.copy()\n",
    "df_features_raw['titles_text'] = df_features_raw[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_dates(df):\n",
    "    count_dates = []\n",
    "    for row in range(df.shape[0]):\n",
    "        string = df['titles_text'].iloc[row]\n",
    "        result = len(re.findall(r'[A-Z]\\w+\\s\\d\\d\\d\\d|in\\s\\d\\d\\d\\d|In\\s\\d\\d\\d\\d|Monday|Tuesday|Wednesday|Thursday|Friday|Saturday|Sunday', string))\n",
    "        count_dates.append(result)\n",
    "    return count_dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dates = count_dates(df_features_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Text Feature Extraction on Pre-processed Data</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_proc = df.copy()\n",
    "df_features_proc['text'] = df_features_proc['text'].map(lambda x: normalization(x, lowercase=False, remove_stops=True, prt_stemming=False, snb_stemming = False, lemmatization = False))\n",
    "df_features_proc['title'] = df_features_proc['title'].map(lambda x: normalization(x, lowercase=False, remove_stops=True, prt_stemming=False, snb_stemming = False, lemmatization = False))\n",
    "df_features_proc['titles_text'] = df_features_proc[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_verbs(df):\n",
    "    count_verbs = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df['titles_text'].iloc[row])\n",
    "        tag = nltk.pos_tag(text)\n",
    "        a = pd.Series(tag)\n",
    "        result = a.map(lambda x: 1 if re.match(r'VB(.*?)', x[1]) else 0).sum()/a.map(lambda x: 1).sum()\n",
    "        count_verbs.append(result)\n",
    "    return count_verbs\n",
    "\n",
    "def count_nouns(df):\n",
    "    count_nouns = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df['titles_text'].iloc[row])\n",
    "        tag = nltk.pos_tag(text)\n",
    "        a = pd.Series(tag)\n",
    "        result = a.map(lambda x: 1 if re.match(r'NN(.*?)', x[1]) else 0).sum()/a.map(lambda x: 1).sum()\n",
    "        count_nouns.append(result)\n",
    "    return count_nouns\n",
    "\n",
    "def count_adjectives(df):\n",
    "    count_adjectives = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df['titles_text'].iloc[row])\n",
    "        tag = nltk.pos_tag(text)\n",
    "        a = pd.Series(tag)\n",
    "        result = a.map(lambda x: 1 if re.match(r'JJ(.*?)', x[1]) else 0).sum()/a.map(lambda x: 1).sum()\n",
    "        count_adjectives.append(result)\n",
    "    return count_adjectives\n",
    "\n",
    "def count_adverbs(df):\n",
    "    count_adverbs = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df['titles_text'].iloc[row])\n",
    "        tag = nltk.pos_tag(text)\n",
    "        a = pd.Series(tag)\n",
    "        result = a.map(lambda x: 1 if re.match(r'RB(.*?)', x[1]) else 0).sum()/a.map(lambda x: 1).sum()\n",
    "        count_adverbs.append(result)\n",
    "    return count_adverbs\n",
    "\n",
    "def count_superlatives(df):\n",
    "    count_superlatives = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df['titles_text'].iloc[row])\n",
    "        tag = nltk.pos_tag(text)\n",
    "        a = pd.Series(tag)\n",
    "        result = a.map(lambda x: 1 if re.match(r'JJS', x[1]) else 0).sum()/a.map(lambda x: 1).sum()\n",
    "        count_superlatives.append(result)\n",
    "    return count_superlatives\n",
    "\n",
    "def count_comparatives(df):\n",
    "    count_comparatives = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df['titles_text'].iloc[row])\n",
    "        tag = nltk.pos_tag(text)\n",
    "        a = pd.Series(tag)\n",
    "        result = a.map(lambda x: 1 if re.match(r'JJR', x[1]) else 0).sum()/a.map(lambda x: 1).sum()\n",
    "        count_comparatives.append(result)\n",
    "    return count_comparatives\n",
    "\n",
    "def count_proper_nouns(df):\n",
    "    count_proper_nouns = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df['titles_text'].iloc[row])\n",
    "        tag = nltk.pos_tag(text)\n",
    "        a = pd.Series(tag)\n",
    "        result = a.map(lambda x: 1 if re.match(r'NNP', x[1]) else 0).sum()/a.map(lambda x: 1).sum()\n",
    "        count_proper_nouns.append(result)\n",
    "    return count_proper_nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_verbs = count_verbs(df_features_proc)\n",
    "count_nouns = count_nouns(df_features_proc)\n",
    "count_adjectives = count_adjectives(df_features_proc)\n",
    "count_superlatives = count_superlatives(df_features_proc)\n",
    "count_comparatives = count_comparatives(df_features_proc)\n",
    "count_proper_nouns = count_proper_nouns(df_features_proc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Text Feature Extraction on Fully Clean Data</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features_clean = df.copy()\n",
    "df_features_clean['text'] = df_features_clean['text'].map(lambda x: normalization(x, lowercase=True, remove_stops=True, prt_stemming=False, snb_stemming = False, lemmatization = True))\n",
    "df_features_clean['title'] = df_features_clean['title'].map(lambda x: normalization(x, lowercase=True, remove_stops=True, prt_stemming=False, snb_stemming = False, lemmatization = True))\n",
    "df_features_clean['titles_text'] = df_features_clean[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(df):\n",
    "    count_words = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df_features_clean['titles_text'].iloc[row])\n",
    "        result = len(text)\n",
    "        count_words.append(result)\n",
    "    return count_words\n",
    "\n",
    "def vocab_diversity(df):\n",
    "    vocab_diversity = []\n",
    "    for row in range(df.shape[0]):\n",
    "        text = nltk.word_tokenize(df['titles_text'].iloc[row])\n",
    "        result = len(set(text))/len(text)\n",
    "        vocab_diversity.append(result)\n",
    "    return vocab_diversity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_words = count_words(df_features_clean)\n",
    "vocab_diversity = vocab_diversity(df_features_clean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Text Feature Extraction EDA</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_list = ['count_dates',\n",
    "                'count_verbs',\n",
    "                'count_nouns',\n",
    "                'count_adjectives',\n",
    "                'count_superlatives',\n",
    "                'count_comparatives',\n",
    "                'count_proper_nouns',\n",
    "                'count_words',\n",
    "                'vocab_diversity']\n",
    "\n",
    "data_tuples = list(zip(count_dates,\n",
    "                       count_verbs,\n",
    "                       count_nouns,\n",
    "                       count_adjectives,\n",
    "                       count_superlatives,\n",
    "                       count_comparatives,\n",
    "                       count_proper_nouns,\n",
    "                       count_words,\n",
    "                       vocab_diversity))\n",
    "\n",
    "df_features = pd.DataFrame(data_tuples, columns = features_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_dates            6.847714\n",
       "count_verbs           -0.738484\n",
       "count_nouns            1.260269\n",
       "count_adjectives      -0.125030\n",
       "count_superlatives    22.565608\n",
       "count_comparatives     6.603347\n",
       "count_proper_nouns     2.087801\n",
       "count_words            4.082407\n",
       "vocab_diversity        1.286070\n",
       "dtype: float64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "columns = list(df_features.columns)\n",
    "\n",
    "df_features[columns] = scaler.fit_transform(df_features[columns]) \n",
    "df_features.skew(axis = 0, skipna = True) # We are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count_dates          -0.006521\n",
       "count_verbs          -0.738484\n",
       "count_nouns          -0.246259\n",
       "count_adjectives     -0.125030\n",
       "count_superlatives    0.176484\n",
       "count_comparatives    0.299286\n",
       "count_proper_nouns    0.287063\n",
       "count_words           0.174797\n",
       "vocab_diversity       1.286070\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skewed_columns = ['count_dates','count_nouns','count_superlatives','count_comparatives',\n",
    "                  'count_proper_nouns','count_words']\n",
    "\n",
    "df_features[skewed_columns] = np.cbrt(df_features[skewed_columns]) # Get the log of the only signficantly skewed column\n",
    "df_features.skew(axis = 0, skipna = True) # We are good to go!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_features['news_label'] = list(df['news_label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col0 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col1 {\n",
       "            background-color:  #bad0f8;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col2 {\n",
       "            background-color:  #86a9fc;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col3 {\n",
       "            background-color:  #a6c4fe;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col4 {\n",
       "            background-color:  #bbd1f8;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col5 {\n",
       "            background-color:  #b6cefa;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col6 {\n",
       "            background-color:  #97b8ff;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col7 {\n",
       "            background-color:  #f39577;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col8 {\n",
       "            background-color:  #779af7;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row0_col9 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col0 {\n",
       "            background-color:  #c3d5f4;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col1 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col2 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col3 {\n",
       "            background-color:  #b9d0f9;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col4 {\n",
       "            background-color:  #9bbcff;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col5 {\n",
       "            background-color:  #9dbdff;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col6 {\n",
       "            background-color:  #4961d2;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col7 {\n",
       "            background-color:  #eed0c0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col8 {\n",
       "            background-color:  #a7c5fe;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row1_col9 {\n",
       "            background-color:  #6f92f3;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col0 {\n",
       "            background-color:  #92b4fe;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col1 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col2 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col3 {\n",
       "            background-color:  #5470de;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col4 {\n",
       "            background-color:  #506bda;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col5 {\n",
       "            background-color:  #465ecf;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col6 {\n",
       "            background-color:  #e57058;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col7 {\n",
       "            background-color:  #92b4fe;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col8 {\n",
       "            background-color:  #f5c0a7;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row2_col9 {\n",
       "            background-color:  #c1d4f4;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col0 {\n",
       "            background-color:  #a7c5fe;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col1 {\n",
       "            background-color:  #afcafc;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col2 {\n",
       "            background-color:  #465ecf;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col3 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col4 {\n",
       "            background-color:  #c4d5f3;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col5 {\n",
       "            background-color:  #d1dae9;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col6 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col7 {\n",
       "            background-color:  #f2cbb7;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col8 {\n",
       "            background-color:  #b3cdfb;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row3_col9 {\n",
       "            background-color:  #92b4fe;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col0 {\n",
       "            background-color:  #cfdaea;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col1 {\n",
       "            background-color:  #aac7fd;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col2 {\n",
       "            background-color:  #6384eb;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col3 {\n",
       "            background-color:  #d6dce4;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col4 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col5 {\n",
       "            background-color:  #bad0f8;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col6 {\n",
       "            background-color:  #6f92f3;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col7 {\n",
       "            background-color:  #f7bca1;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col8 {\n",
       "            background-color:  #96b7ff;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row4_col9 {\n",
       "            background-color:  #85a8fc;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col0 {\n",
       "            background-color:  #ccd9ed;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col1 {\n",
       "            background-color:  #aec9fc;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col2 {\n",
       "            background-color:  #5b7ae5;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col3 {\n",
       "            background-color:  #e0dbd8;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col4 {\n",
       "            background-color:  #bcd2f7;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col5 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col6 {\n",
       "            background-color:  #5d7ce6;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col7 {\n",
       "            background-color:  #f7ba9f;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col8 {\n",
       "            background-color:  #9abbff;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row5_col9 {\n",
       "            background-color:  #779af7;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col0 {\n",
       "            background-color:  #98b9ff;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col1 {\n",
       "            background-color:  #3d50c3;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col2 {\n",
       "            background-color:  #e7745b;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col3 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col4 {\n",
       "            background-color:  #506bda;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col5 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col6 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col7 {\n",
       "            background-color:  #8badfd;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col8 {\n",
       "            background-color:  #f3c8b2;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row6_col9 {\n",
       "            background-color:  #c9d7f0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col0 {\n",
       "            background-color:  #f7ac8e;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col1 {\n",
       "            background-color:  #cfdaea;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col2 {\n",
       "            background-color:  #4961d2;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col3 {\n",
       "            background-color:  #dedcdb;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col4 {\n",
       "            background-color:  #e3d9d3;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col5 {\n",
       "            background-color:  #e3d9d3;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col6 {\n",
       "            background-color:  #4e68d8;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col7 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col8 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row7_col9 {\n",
       "            background-color:  #6b8df0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col0 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col1 {\n",
       "            background-color:  #6384eb;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col2 {\n",
       "            background-color:  #e5d8d1;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col3 {\n",
       "            background-color:  #7ea1fa;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col4 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col5 {\n",
       "            background-color:  #3d50c3;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col6 {\n",
       "            background-color:  #e2dad5;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col7 {\n",
       "            background-color:  #3b4cc0;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col8 {\n",
       "            background-color:  #b40426;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row8_col9 {\n",
       "            background-color:  #b1cbfc;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col0 {\n",
       "            background-color:  #4b64d5;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col1 {\n",
       "            background-color:  #7396f5;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col2 {\n",
       "            background-color:  #c3d5f4;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col3 {\n",
       "            background-color:  #9fbfff;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col4 {\n",
       "            background-color:  #779af7;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col5 {\n",
       "            background-color:  #6687ed;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col6 {\n",
       "            background-color:  #d2dbe8;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col7 {\n",
       "            background-color:  #b1cbfc;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col8 {\n",
       "            background-color:  #dedcdb;\n",
       "        }    #T_da2ccd66_849b_11e9_9e32_acde48001122row9_col9 {\n",
       "            background-color:  #b40426;\n",
       "        }</style>  \n",
       "<table id=\"T_da2ccd66_849b_11e9_9e32_acde48001122\" > \n",
       "<thead>    <tr> \n",
       "        <th class=\"blank level0\" ></th> \n",
       "        <th class=\"col_heading level0 col0\" >count_dates</th> \n",
       "        <th class=\"col_heading level0 col1\" >count_verbs</th> \n",
       "        <th class=\"col_heading level0 col2\" >count_nouns</th> \n",
       "        <th class=\"col_heading level0 col3\" >count_adjectives</th> \n",
       "        <th class=\"col_heading level0 col4\" >count_superlatives</th> \n",
       "        <th class=\"col_heading level0 col5\" >count_comparatives</th> \n",
       "        <th class=\"col_heading level0 col6\" >count_proper_nouns</th> \n",
       "        <th class=\"col_heading level0 col7\" >count_words</th> \n",
       "        <th class=\"col_heading level0 col8\" >vocab_diversity</th> \n",
       "        <th class=\"col_heading level0 col9\" >FAKE</th> \n",
       "    </tr></thead> \n",
       "<tbody>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row0\" class=\"row_heading level0 row0\" >count_dates</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col0\" class=\"data row0 col0\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col1\" class=\"data row0 col1\" >0.13</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col2\" class=\"data row0 col2\" >-0.084</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col3\" class=\"data row0 col3\" >0.0059</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col4\" class=\"data row0 col4\" >0.19</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col5\" class=\"data row0 col5\" >0.17</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col6\" class=\"data row0 col6\" >-0.058</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col7\" class=\"data row0 col7\" >0.56</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col8\" class=\"data row0 col8\" >-0.47</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row0_col9\" class=\"data row0 col9\" >-0.39</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row1\" class=\"row_heading level0 row1\" >count_verbs</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col0\" class=\"data row1 col0\" >0.13</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col1\" class=\"data row1 col1\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col2\" class=\"data row1 col2\" >-0.41</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col3\" class=\"data row1 col3\" >0.084</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col4\" class=\"data row1 col4\" >0.062</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col5\" class=\"data row1 col5\" >0.077</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col6\" class=\"data row1 col6\" >-0.4</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col7\" class=\"data row1 col7\" >0.23</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col8\" class=\"data row1 col8\" >-0.23</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row1_col9\" class=\"data row1 col9\" >-0.16</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row2\" class=\"row_heading level0 row2\" >count_nouns</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col0\" class=\"data row2 col0\" >-0.084</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col1\" class=\"data row2 col1\" >-0.41</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col2\" class=\"data row2 col2\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col3\" class=\"data row2 col3\" >-0.35</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col4\" class=\"data row2 col4\" >-0.22</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col5\" class=\"data row2 col5\" >-0.26</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col6\" class=\"data row2 col6\" >0.77</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col7\" class=\"data row2 col7\" >-0.34</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col8\" class=\"data row2 col8\" >0.34</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row2_col9\" class=\"data row2 col9\" >0.17</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row3\" class=\"row_heading level0 row3\" >count_adjectives</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col0\" class=\"data row3 col0\" >0.0059</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col1\" class=\"data row3 col1\" >0.084</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col2\" class=\"data row3 col2\" >-0.35</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col3\" class=\"data row3 col3\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col4\" class=\"data row3 col4\" >0.23</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col5\" class=\"data row3 col5\" >0.28</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col6\" class=\"data row3 col6\" >-0.47</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col7\" class=\"data row3 col7\" >0.27</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col8\" class=\"data row3 col8\" >-0.16</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row3_col9\" class=\"data row3 col9\" >-0.022</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row4\" class=\"row_heading level0 row4\" >count_superlatives</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col0\" class=\"data row4 col0\" >0.19</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col1\" class=\"data row4 col1\" >0.062</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col2\" class=\"data row4 col2\" >-0.22</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col3\" class=\"data row4 col3\" >0.23</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col4\" class=\"data row4 col4\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col5\" class=\"data row4 col5\" >0.19</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col6\" class=\"data row4 col6\" >-0.22</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col7\" class=\"data row4 col7\" >0.37</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col8\" class=\"data row4 col8\" >-0.32</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row4_col9\" class=\"data row4 col9\" >-0.072</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row5\" class=\"row_heading level0 row5\" >count_comparatives</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col0\" class=\"data row5 col0\" >0.17</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col1\" class=\"data row5 col1\" >0.077</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col2\" class=\"data row5 col2\" >-0.26</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col3\" class=\"data row5 col3\" >0.28</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col4\" class=\"data row5 col4\" >0.19</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col5\" class=\"data row5 col5\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col6\" class=\"data row5 col6\" >-0.31</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col7\" class=\"data row5 col7\" >0.38</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col8\" class=\"data row5 col8\" >-0.3</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row5_col9\" class=\"data row5 col9\" >-0.13</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row6\" class=\"row_heading level0 row6\" >count_proper_nouns</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col0\" class=\"data row6 col0\" >-0.058</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col1\" class=\"data row6 col1\" >-0.4</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col2\" class=\"data row6 col2\" >0.77</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col3\" class=\"data row6 col3\" >-0.47</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col4\" class=\"data row6 col4\" >-0.22</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col5\" class=\"data row6 col5\" >-0.31</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col6\" class=\"data row6 col6\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col7\" class=\"data row6 col7\" >-0.38</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col8\" class=\"data row6 col8\" >0.3</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row6_col9\" class=\"data row6 col9\" >0.21</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row7\" class=\"row_heading level0 row7\" >count_words</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col0\" class=\"data row7 col0\" >0.56</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col1\" class=\"data row7 col1\" >0.23</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col2\" class=\"data row7 col2\" >-0.34</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col3\" class=\"data row7 col3\" >0.27</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col4\" class=\"data row7 col4\" >0.37</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col5\" class=\"data row7 col5\" >0.38</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col6\" class=\"data row7 col6\" >-0.38</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col7\" class=\"data row7 col7\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col8\" class=\"data row7 col8\" >-0.82</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row7_col9\" class=\"data row7 col9\" >-0.18</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row8\" class=\"row_heading level0 row8\" >vocab_diversity</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col0\" class=\"data row8 col0\" >-0.47</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col1\" class=\"data row8 col1\" >-0.23</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col2\" class=\"data row8 col2\" >0.34</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col3\" class=\"data row8 col3\" >-0.16</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col4\" class=\"data row8 col4\" >-0.32</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col5\" class=\"data row8 col5\" >-0.3</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col6\" class=\"data row8 col6\" >0.3</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col7\" class=\"data row8 col7\" >-0.82</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col8\" class=\"data row8 col8\" >1</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row8_col9\" class=\"data row8 col9\" >0.098</td> \n",
       "    </tr>    <tr> \n",
       "        <th id=\"T_da2ccd66_849b_11e9_9e32_acde48001122level0_row9\" class=\"row_heading level0 row9\" >FAKE</th> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col0\" class=\"data row9 col0\" >-0.39</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col1\" class=\"data row9 col1\" >-0.16</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col2\" class=\"data row9 col2\" >0.17</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col3\" class=\"data row9 col3\" >-0.022</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col4\" class=\"data row9 col4\" >-0.072</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col5\" class=\"data row9 col5\" >-0.13</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col6\" class=\"data row9 col6\" >0.21</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col7\" class=\"data row9 col7\" >-0.18</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col8\" class=\"data row9 col8\" >0.098</td> \n",
       "        <td id=\"T_da2ccd66_849b_11e9_9e32_acde48001122row9_col9\" class=\"data row9 col9\" >1</td> \n",
       "    </tr></tbody> \n",
       "</table> "
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7fce65881b00>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dummies = pd.get_dummies(df_features['news_label'])\n",
    "del df_dummies[df_dummies.columns[-1]]\n",
    "df_new = pd.concat([df_features, df_dummies], axis=1)\n",
    "del df_new['news_label']\n",
    "\n",
    "corr = df_new.corr()\n",
    "corr.style.background_gradient(cmap='coolwarm').set_precision(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_features['news_label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Text Classification with Features - Tentative</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FE = df.copy()\n",
    "df_FE['text'] = df_FE['text'].map(lambda x: normalization(x, lowercase=True, remove_stops=False, prt_stemming=True, snb_stemming = False, lemmatization = False))\n",
    "df_FE['title'] = df_FE['title'].map(lambda x: normalization(x, lowercase=True, remove_stops=False, prt_stemming=True, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_FE['titles_text'] = df_FE[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the `tfidf_vectorizer` \n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.5, ngram_range=(1, 3), norm = 'l2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit and transform the training data \n",
    "df_text = pd.DataFrame(tfidf_vectorizer.fit_transform(df_FE['titles_text']).toarray()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_text['count_dates'] = df_features['count_dates']\n",
    "\n",
    "#X_train, X_test, y_train, y_test = train_test_split(df_text, y, test_size=0.2, random_state=666, shuffle = False)\n",
    "\n",
    "#pipe = Pipeline([('PAC', PassiveAggressiveClassifier(random_state = 69))])\n",
    "\n",
    "#pipe_params = {'PAC__max_iter': [100, 500]}\n",
    "\n",
    "#gs = GridSearchCV(pipe, param_grid=pipe_params, cv=3)\n",
    "#gs.fit(X_train, y_train);\n",
    "#print(\"Best score:\", gs.best_score_)\n",
    "#print(\"Train score\", gs.score(X_train, y_train))\n",
    "#print(\"Test score\", gs.score(X_test, y_test))\n",
    "#gs.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Isolating Words Based on POS</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another attemps was made to extract features from the news dataset. Instead of running a machine learning algorithm on all tokens of the 'titles_text' column, the algorithm was trained only on words with a specific POS tag. The relevant POS tags included the following:\n",
    "\n",
    "**1/ POS tag beginning with NN**: Nouns are the most significant tokens among the articles. \n",
    "\n",
    "**2/ POS tag beginning with VB**: Verbs in all their forms were extracted. \n",
    "\n",
    "**3/ POS tag beginning with JJ**: The POS tags beginning with JJ also include comparatives and superlatives. \n",
    "\n",
    "**4/ POS tag beginning with RB**: Aderbs in all their forms were extracted. Since they often include the suffix 'ly', the text could not be in lemmatized or stemmed form to extract the POS tags.  \n",
    "\n",
    "**5/ POS tag FW**: The 'foreign word' POS tag, typically indicative of a rich vocabulary and culture from real news, was also attributed to misspelled words from fake news, and performed poorly on the algorithm. \n",
    "\n",
    "**6/ POS tag MD**: The 'modal auxiliary' POS tag is very common among all articles, and performed poorly. \n",
    "\n",
    "**7/ POS tag UH**: The 'interjection' POS tag was present in very few articles, which impeded our model's ability to train on those features. \n",
    "\n",
    "**8/ POS tag LS**: The 'list marker' POS tag was present in very few articles, which impeded our model's ability to train on those features. \n",
    "\n",
    "After running the algorithm on the above POS tags individually and in various combinations, the **highest accuracy score was 93.5%** and included all tokens with POS tags starting with 'NN', 'VB', and 'RB'; i.e. all nouns, verbs, and adverbs. The worst scores were obtained by including the 'MD' and 'UH' POS tags. 'MD' tags were present in nearly all articles, real or fake, and 'UH' tags were very scarce across the dataset. \n",
    "\n",
    "Though the accuracy score obtained using nouns, verbs, and adverbs was relatively high, it still did not perform as well as the optimal cross-validation score of 93.9% by including all tokens. It does however demonstrate that the most relevant tokens for this text classification algorithm are nouns, verbs, and adverbs. Such tokens are key in differentiating fake news from real news. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = df.copy()\n",
    "df_pos['text'] = df_pos['text'].map(lambda x: normalization(x, lowercase=False, remove_stops=True, prt_stemming=False, snb_stemming = False, lemmatization = False))\n",
    "df_pos['title'] = df_pos['title'].map(lambda x: normalization(x, lowercase=False, remove_stops=True, prt_stemming=False, snb_stemming = False, lemmatization = False))\n",
    "df_pos['titles_text'] = df_pos[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_nouns(df):\n",
    "    extract_nouns = []\n",
    "    for row in range(df.shape[0]):\n",
    "        txt = df['titles_text'].iloc[row]\n",
    "        nouns = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if re.match(r'NN(.*?)', pos)]\n",
    "        nouns = \" \".join(nouns)\n",
    "        extract_nouns.append(nouns)\n",
    "    return extract_nouns\n",
    "\n",
    "def extract_verbs(df):\n",
    "    extract_verbs = []\n",
    "    for row in range(df.shape[0]):\n",
    "        txt = df['titles_text'].iloc[row]\n",
    "        verbs = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if re.match(r'VB(.*?)', pos)]\n",
    "        verbs = \" \".join(verbs)\n",
    "        extract_verbs.append(verbs)\n",
    "    return extract_verbs\n",
    "\n",
    "def extract_adj(df):\n",
    "    extract_adj = []\n",
    "    for row in range(df.shape[0]):\n",
    "        txt = df['titles_text'].iloc[row]\n",
    "        adj = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if re.match(r'JJ(.*?)', pos)]\n",
    "        adj = \" \".join(adj)\n",
    "        extract_adj.append(adj)\n",
    "    return extract_adj\n",
    "\n",
    "def extract_adv(df):\n",
    "    extract_adv = []\n",
    "    for row in range(df.shape[0]):\n",
    "        txt = df['titles_text'].iloc[row]\n",
    "        adv = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if re.match(r'RB(.*?)', pos)]\n",
    "        adv = \" \".join(adv)\n",
    "        extract_adv.append(adv)\n",
    "    return extract_adv\n",
    "\n",
    "def extract_interjections(df):\n",
    "    extract_uh = []\n",
    "    for row in range(df.shape[0]):\n",
    "        txt = df['titles_text'].iloc[row]\n",
    "        uh = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if re.match(r'US(.*?)', pos)]\n",
    "        uh = \" \".join(uh)\n",
    "        extract_uh.append(uh)\n",
    "    return extract_uh\n",
    "\n",
    "def extract_foreign_words(df):\n",
    "    extract_fw = []\n",
    "    for row in range(df.shape[0]):\n",
    "        txt = df['titles_text'].iloc[row]\n",
    "        fw = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if re.match(r'FW(.*?)', pos)]\n",
    "        fw = \" \".join(fw)\n",
    "        extract_fw.append(fw)\n",
    "    return extract_fw\n",
    "\n",
    "def extract_modal(df):\n",
    "    extract_md = []\n",
    "    for row in range(df.shape[0]):\n",
    "        txt = df['titles_text'].iloc[row]\n",
    "        md = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if re.match(r'MD(.*?)', pos)]\n",
    "        md = \" \".join(md)\n",
    "        extract_md.append(md)\n",
    "    return extract_md\n",
    "\n",
    "def extract_list_marker(df):\n",
    "    extract_ls = []\n",
    "    for row in range(df.shape[0]):\n",
    "        txt = df['titles_text'].iloc[row]\n",
    "        ls = [word for (word, pos) in nltk.pos_tag(nltk.word_tokenize(txt)) if re.match(r'LS(.*?)', pos)]\n",
    "        ls = \" \".join(ls)\n",
    "        extract_ls.append(ls)\n",
    "    return extract_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_nouns = extract_nouns(df_pos)\n",
    "extract_verbs = extract_verbs(df_pos)\n",
    "extract_adj = extract_adj(df_pos)\n",
    "extract_adv = extract_adv(df_pos)\n",
    "extract_uh = extract_interjections(df_pos)\n",
    "extract_fw = extract_foreign_words(df_pos)\n",
    "extract_md = extract_modal(df_pos)\n",
    "extract_ls = extract_list_marker(df_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos['nouns'] = extract_nouns\n",
    "df_pos['verbs'] = extract_verbs\n",
    "df_pos['adjectives'] = extract_adj\n",
    "df_pos['adverbs'] = extract_adv\n",
    "df_pos['foreign words'] = extract_fw\n",
    "df_pos['interjections'] = extract_uh\n",
    "df_pos['modal'] = extract_md\n",
    "df_pos['list marker'] = extract_ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:lightslategray\">Modelling on isolated POS</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, the team tried isolating the effect of the different POS. The team also tried combination of different isolated POS. Nouns explain most of the variance. However, combinin different POS lead to better performance that using only one POS. In fact, the best score in this section was obtained when blablabla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean2(dataframe):\n",
    "    'Function that takes the dataframe as an input and cleans it by removing punction, digits and strips'\n",
    "    #Removing punctuation\n",
    "    dataframe.title = dataframe.title.apply(lambda x: x.translate(str.maketrans('', '', string.punctuation)))\n",
    "    dataframe.text = dataframe.text.apply(lambda x: x.translate(str.maketrans('','', string.punctuation)))\n",
    "    #Removing regular expressions\n",
    "    dataframe['title'] = dataframe['title'].str.replace('[^\\w\\s]',' ')\n",
    "    dataframe['text'] = dataframe['text'].str.replace('[^\\w\\s]',' ')\n",
    "    #Removing digits\n",
    "    dataframe.title = dataframe.title.apply(lambda x: x.translate(str.maketrans('', '', string.digits)))\n",
    "    dataframe.text = dataframe.text.apply(lambda x: x.translate(str.maketrans('','', string.digits)))\n",
    "    #Removing double spaces\n",
    "    dataframe['title'] = dataframe['title'].str.replace('  ',' ')\n",
    "    dataframe['text'] = dataframe['text'].str.replace('  ',' ')\n",
    "    #Removing strips\n",
    "    dataframe['title'] = dataframe['title'].replace(r'\\s+|\\\\n', ' ', regex = True, inplace = False)\n",
    "    dataframe['text'] = dataframe['text'].replace(r'\\s+|\\\\n', ' ', regex = True, inplace = False)\n",
    "    return dataframe\n",
    "\n",
    "def normalization2(text, lowercase = False, remove_stops = False, prt_stemming = False, snb_stemming = False, lemmatization = False):\n",
    "    'Flexible function to try effect of removing stopwords and the different stemming techniques'\n",
    "    txt = str(text)\n",
    "    if lowercase:\n",
    "        txt = \" \".join([w.lower() for w in txt.split()])\n",
    "    if remove_stops:\n",
    "        txt = \" \".join([w for w in txt.split() if w not in stops])\n",
    "    if prt_stemming:\n",
    "        st = PorterStemmer()\n",
    "        txt = \" \".join([st.stem(w) for w in txt.split()])\n",
    "    if snb_stemming:\n",
    "        snb = SnowballStemmer('english')\n",
    "        txt = \" \".join([snb.stem(w) for w in txt.split()])\n",
    "    if lemmatization:\n",
    "        wordnet_lemmatizer = WordNetLemmatizer()\n",
    "        txt = \" \".join([wordnet_lemmatizer.lemmatize(w, pos = 's') for w in txt.split()])\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1 = df_pos.copy()\n",
    "basic_clean(df_pos1)\n",
    "df_pos1['adverbs'] = df_pos1['adverbs'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['adverbs'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.673\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1['nouns'] = df_pos1['nouns'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['nouns'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.928\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1['verbs'] = df_pos1['verbs'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['verbs'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.816\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1['adjectives'] = df_pos1['adjectives'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['adjectives'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.807\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1['foreign words'] = df_pos1['foreign words'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbs and Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Title and Text\n",
    "df_pos1['verbs_nouns'] = df_pos1[['verbs', 'nouns']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1['verbs_nouns'] = df_pos1['verbs_nouns'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['verbs_nouns'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.931\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjectives and Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Title and Text\n",
    "df_pos1['adj_nouns'] = df_pos1[['adjectives', 'nouns']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1['adj_nouns'] = df_pos1['adj_nouns'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['adj_nouns'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.926\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbs and Adjectives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Title and Text\n",
    "df_pos1['adj_verbs'] = df_pos1[['adjectives', 'verbs']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos1['adj_verbs'] = df_pos1['adj_verbs'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['adj_verbs'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.863\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verbs, Adjectives and Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Title and Text\n",
    "df_pos1['all'] = df_pos1[['adjectives', 'verbs', 'nouns']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_clean2(df_pos1)\n",
    "df_pos1['all'] = df_pos1['all'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further cleaning\n",
    "df_pos1['all'] = df_pos1['all'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "df_pos1['all'] = df_pos1['all'].str.replace('[0-9]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['all'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.934\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df = 0.75) \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(random_state=11), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nouns, Verbs and Adverbs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging Title and Text\n",
    "df_pos1['all2'] = df_pos1[['nouns', 'verbs', 'adverbs']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_clean2(df_pos1)\n",
    "df_pos1['all2'] = df_pos1['all2'].map(lambda x: normalization2(x, lowercase=True, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Further cleaning\n",
    "df_pos1['all2'] = df_pos1['all2'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "df_pos1['all2'] = df_pos1['all2'].str.replace('[0-9]','')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make training and test sets \n",
    "X_train, X_test, y_train, y_test = train_test_split(df_pos1['all2'], y, test_size=0.2, random_state=666)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Cross-Validation score:  0.935\n"
     ]
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer() \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(X_train) \n",
    "tfidf_test = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "cv_scores = cross_val_score(PassiveAggressiveClassifier(random_state=11), tfidf_train,y_train,cv=10,n_jobs=-1)\n",
    "mean_score = round(np.mean(cv_scores), 3)\n",
    "print(\"Mean Cross-Validation score: \",mean_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">VI. Predicting on Test Set</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, the optimal data cleaning processes and hyperparameters for this text classification exercise are the following:\n",
    "\n",
    "1/ Removing regular expressions '^\\w\\s'; which represents a one-letter word at the beginning of the article. For instance, it removes the 'A' if it were an article were beginning with 'A thing of the past ...'.\n",
    "\n",
    "2/ Punctuation was also removed from the both titles and texts.\n",
    "\n",
    "3/ Satellite adjectives were also lemmatized. \n",
    "\n",
    "The tfidf vectorizer was optimized with the following hyperparameter:\n",
    "\n",
    "1/ 'max_df' was set at 1.0: this implied no token was removed from the dataset because it appeared too frequently. \n",
    "\n",
    "2/ 'ngram_range' was set at (1, 2): 1 was the lower boundary and 2 was the upper boundary for the n-grams to be extracted from the sentence to determine the POS tag of a particular word.\n",
    "\n",
    "3/ 'norm' was set to 'l2': This is the default setting by which the sum of squares of all numbers in the vector is equal to 1. \n",
    "\n",
    "The algorithm with the highest overall performance was the passive aggressive classifier. The latter minimizes the loss function aggressivaly, while being conservative when training. The classifier does not overreact a positive classification on the training dataset. The passive aggressive classifier was optimized with the following hyperparameter:\n",
    "\n",
    "1/ The loss argument was set at 'hinge': The hinge function takes the maximum of 1 minus the label in question multiplied by the classifier times the data point for each mistaken prediction. The algorithm takes the square of the classifier for a correct prediction, though computes the loss in a linear fashion when set to 'hinge'. This means that the function is aggressive in reducing the loss quickly, as opposed to the 0-1 loss function. The latter would impose a penalty of 1 for mistaken predictions, and no penalty for a correct prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10498</td>\n",
       "      <td>September New Homes Sales Rise——-Back To 1992 ...</td>\n",
       "      <td>September New Homes Sales Rise Back To 1992 Le...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2439</td>\n",
       "      <td>Why The Obamacare Doomsday Cult Can't Admit It...</td>\n",
       "      <td>But when Congress debated and passed the Patie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>864</td>\n",
       "      <td>Sanders, Cruz resist pressure after NY losses,...</td>\n",
       "      <td>The Bernie Sanders and Ted Cruz campaigns vowe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4128</td>\n",
       "      <td>Surviving escaped prisoner likely fatigued and...</td>\n",
       "      <td>Police searching for the second of two escaped...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>662</td>\n",
       "      <td>Clinton and Sanders neck and neck in Californi...</td>\n",
       "      <td>No matter who wins California's 475 delegates ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID                                              title  \\\n",
       "0  10498  September New Homes Sales Rise——-Back To 1992 ...   \n",
       "1   2439  Why The Obamacare Doomsday Cult Can't Admit It...   \n",
       "2    864  Sanders, Cruz resist pressure after NY losses,...   \n",
       "3   4128  Surviving escaped prisoner likely fatigued and...   \n",
       "4    662  Clinton and Sanders neck and neck in Californi...   \n",
       "\n",
       "                                                text  \n",
       "0  September New Homes Sales Rise Back To 1992 Le...  \n",
       "1  But when Congress debated and passed the Patie...  \n",
       "2  The Bernie Sanders and Ted Cruz campaigns vowe...  \n",
       "3  Police searching for the second of two escaped...  \n",
       "4  No matter who wins California's 475 delegates ...  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the new Training dataset\n",
    "url = \"https://raw.githubusercontent.com/jonathanserrano1993/Fake_news_detection_NLP/master/fake_or_real_news_test.csv\"\n",
    "s = requests.get(url).content\n",
    "df_test = pd.read_csv(io.StringIO(s.decode('utf-8')), sep=',')\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Processing on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = df_test.copy()\n",
    "basic_clean(test)\n",
    "\n",
    "# Further cleaning\n",
    "test['text'] = test['text'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "test['title'] = test['title'].map(lambda x: re.sub(r'\\W+', ' ', x))\n",
    "\n",
    "# Lowercase and lemmatizing on satellite adjectives\n",
    "test['text'] = test['text'].map(lambda x: normalization(x, lowercase=False, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = True))\n",
    "test['title'] = test['title'].map(lambda x: normalization(x, lowercase=False, remove_stops=False, prt_stemming=False, snb_stemming = False, lemmatization = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['titles_text'] = test[['title', 'text']].apply(lambda x: ' '.join(x), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Best Performing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['FAKE', 'REAL', 'REAL', ..., 'FAKE', 'REAL', 'REAL'], dtype='<U4')"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#set my model to DecisionTree\n",
    "model = PassiveAggressiveClassifier(loss = 'hinge', random_state = 69)\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df = 1.0, norm = 'l2', ngram_range = (1,2)) \n",
    "tfidf_train = tfidf_vectorizer.fit_transform(df1['titles_text']) \n",
    "tfidf_test = tfidf_vectorizer.transform(test['titles_text'])\n",
    "\n",
    "#set prediction data to factors that will predict, and set target to SalePrice\n",
    "train_data = tfidf_train\n",
    "test_data = tfidf_test\n",
    "target = y\n",
    "\n",
    "#fitting model with prediction data and telling it my target\n",
    "model.fit(train_data, target)\n",
    "\n",
    "model.predict(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['prediction'] = list(model.predict(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = test[['ID','prediction']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.to_csv('NLP_paul_jonathan.csv', encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <span style=\"color:darkblue\">Thank you!</span> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://i.ibb.co/hdsP0W4/tumblr-otxq0p-WDSh1s2791bo1-1280.gif\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image(url= \"https://i.ibb.co/hdsP0W4/tumblr-otxq0p-WDSh1s2791bo1-1280.gif\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
